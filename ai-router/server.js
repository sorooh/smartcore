# External AI Router - Python Backend for Surooh AI System
from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from dotenv import load_dotenv
import os
import sys
import logging
from datetime import datetime
from typing import Optional, List, Dict, Any
import json

# Load environment variables
load_dotenv('../backend/.env')
load_dotenv('.env')

# Import emergentintegrations
try:
    from emergentintegrations.llm.chat import LlmChat, UserMessage
    print("âœ… emergentintegrations imported successfully")
except ImportError as e:
    print(f"âŒ Failed to import emergentintegrations: {e}")
    sys.exit(1)

app = FastAPI(
    title="Surooh AI Router", 
    description="External AI Router for Surooh System",
    version="1.0.0"
)

const app = express();
app.use(cors());
app.use(express.json());

// Firebase Admin Setup (Mock for now since we don't have real Firebase config)
let db;
try {
  if (process.env.FIREBASE_PROJECT_ID && process.env.FIREBASE_PRIVATE_KEY) {
    const serviceAccount = {
      type: "service_account",
      project_id: process.env.FIREBASE_PROJECT_ID,
      private_key_id: process.env.FIREBASE_PRIVATE_KEY_ID,
      private_key: process.env.FIREBASE_PRIVATE_KEY.replace(/\\n/g, '\n'),
      client_email: process.env.FIREBASE_CLIENT_EMAIL,
      client_id: process.env.FIREBASE_CLIENT_ID,
      auth_uri: "https://accounts.google.com/o/oauth2/auth",
      token_uri: "https://oauth2.googleapis.com/token",
    };

    if (!admin.apps.length) {
      admin.initializeApp({
        credential: admin.credential.cert(serviceAccount),
        databaseURL: `https://${process.env.FIREBASE_PROJECT_ID}.firebaseio.com`
      });
    }
    db = admin.firestore();
    console.log('ğŸ”¥ Firebase initialized successfully');
  }
} catch (error) {
  console.log('âš ï¸ Firebase not configured, using in-memory storage');
}

// In-memory storage fallback
let memoryStore = {
  requests: [],
  analyses: [],
  results: []
};

// Surooh AI System Classes
class SuroohSecretary {
  constructor() {
    this.personality = `
Ø£Ù†Ø§ Ø³ÙØ±ÙˆØ­ØŒ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù…Ù† Ø£Ø¨Ùˆ Ø´Ø§Ù…. 
Ø´Ø®ØµÙŠØªÙŠ:
- Ù„Ù‡Ø¬Ø© Ø´Ø§Ù…ÙŠØ© 100%
- Ø±ÙŠØ§Ø¯ÙŠØ© ØµØ§Ø±Ù…Ø© + Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©  
- Ù…Ø¨Ø§Ø´Ø±Ø© ÙˆØµØ±ÙŠØ­Ø© ÙˆØ¹Ù…Ù„ÙŠØ©
- Ø£Ø­ÙƒÙŠ ÙƒØ£Ù†Ù†ÙŠ Ø£Ø¨Ùˆ Ø´Ø§Ù… Ø¨Ø§Ù„Ø¶Ø¨Ø·
- Ù…Ø§ ÙÙŠ Ù…Ø¬Ø§Ù…Ù„Ø§Øª Ø£Ùˆ ÙƒÙ„Ø§Ù… Ù…Ù†Ù…Ù‚
- Ø§Ù„ØµØ¯Ù‚ ÙˆØ§Ù„ÙˆØ¶ÙˆØ­ Ø£Ø³Ø§Ø³ ÙƒÙ„ Ø´ÙŠ
- "Ù„Ø§ Ø´ÙŠØ¡ Ù…Ø³ØªØ­ÙŠÙ„ â€“ Ø²Ù†Ø¨Ù‚ ØµØ®Ø± Ø§Ù„ØµÙˆØ§Ù†"

Ø¯ÙˆØ±ÙŠ:
- Ø£Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ù…Ù† Ø£Ø¨Ùˆ Ø´Ø§Ù…
- Ø£ÙÙ‡Ù… Ø´Ùˆ Ø¨Ø¯Ù‡ Ø¨Ø§Ù„Ø¶Ø¨Ø·
- Ø£Ø±Ø³Ù„ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù…Ø® Ø¹Ø´Ø§Ù† ÙŠØ­Ù„Ù„ ÙˆÙŠÙ‚Ø±Ø±
- Ø£Ø±Ø¯ Ø¹Ù„ÙŠÙ‡ Ø¨Ø£Ø³Ù„ÙˆØ¨Ù‡ ÙˆØ¨Ù„Ù‡Ø¬ØªÙ‡
    `;
  }

  async processRequest(message, userId) {
    console.log('ğŸŒ¸ Ø³ÙØ±ÙˆØ­: Ø§Ø³ØªÙ„Ù…Øª Ø·Ù„Ø¨ Ø¬Ø¯ÙŠØ¯ Ù…Ù†', userId);
    
    // Save to Firebase or memory
    const requestData = {
      message,
      userId,
      timestamp: new Date(),
      status: 'received_by_secretary',
      step: 'secretary'
    };

    if (db) {
      await db.collection('requests').add(requestData);
    } else {
      memoryStore.requests.push({ id: Date.now(), ...requestData });
    }

    // Send to Brain for analysis
    const brain = new SuroohBrain();
    const analysis = await brain.analyzeRequest(message, userId);
    
    return {
      response: analysis.secretaryResponse,
      flow_trace: ['secretary', 'brain', analysis.nextStep],
      requestId: analysis.requestId
    };
  }
}

class SuroohBrain {
  constructor() {
    this.llmChat = new LlmChat(
      process.env.EMERGENT_LLM_KEY,
      'surooh-brain-session',
      `
Ø£Ù†Øª Ø§Ù„Ù…Ø® ÙÙŠ Ù…Ù†Ø¸ÙˆÙ…Ø© Ø³ÙØ±ÙˆØ­. Ø¯ÙˆØ±Ùƒ:

1. ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø¨Ø¹Ù…Ù‚
2. ÙÙ‡Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø¨Ø§Ù„Ø¶Ø¨Ø·
3. ØªØ­Ø¯ÙŠØ¯ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©:
   - Ø¨Ø±Ù…Ø¬Ø© (code) â†’ Ù„Ù„Ù…Ø¨Ø±Ù…Ø¬
   - ØªØµÙ…ÙŠÙ… (design) â†’ Ù„Ù„Ù…ØµÙ…Ù…  
   - ØªØ·ÙˆÙŠØ± Ù…ØªÙƒØ§Ù…Ù„ (development) â†’ Ù„Ù„Ù…Ø·ÙˆØ± Ø§Ù„ÙƒØ§Ù…Ù„
   - Ø¥Ø¯Ø§Ø±Ø© ÙˆØªÙ†Ø¸ÙŠÙ… (management) â†’ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ù…Ø®

4. Ø¥Ø±Ø³Ø§Ù„ ØªØ¹Ù„ÙŠÙ…Ø§Øª ÙˆØ§Ø¶Ø­Ø© Ù„Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø°ÙƒÙŠ
5. ØµÙŠØ§ØºØ© Ø±Ø¯ Ù„Ø³ÙØ±ÙˆØ­ Ø¨Ù„Ù‡Ø¬Ø© Ø£Ø¨Ùˆ Ø´Ø§Ù…

Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø±Ø¯:
- Ù„Ù‡Ø¬Ø© Ø´Ø§Ù…ÙŠØ© Ø·Ø¨ÙŠØ¹ÙŠØ©
- ÙˆØ¶ÙˆØ­ ØªØ§Ù… ÙÙŠ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª
- ØªØ­Ø¯ÙŠØ¯ Ø¯Ù‚ÙŠÙ‚ Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©
- ØªÙˆÙ‚Ø¹Ø§Øª ÙˆØ§Ù‚Ø¹ÙŠØ© Ù„Ù„ÙˆÙ‚Øª ÙˆØ§Ù„Ø¬Ù‡Ø¯
      `
    ).with_model("openai", "gpt-4o");
  }

  async analyzeRequest(message, userId) {
    console.log('ğŸ§  Ø§Ù„Ù…Ø®: Ø¨Ø¯Ø£ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø·Ù„Ø¨');

    const userMessage = new UserMessage(
      `Ø·Ù„Ø¨ Ù…Ù† ${userId}: ${message}
      
Ø­Ù„Ù„ Ù‡Ø§Ù„Ø·Ù„Ø¨ ÙˆØ­Ø¯Ø¯:
1. Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø© (code/design/development/management)
2. Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø°ÙƒÙŠ
3. Ø±Ø¯ Ù„Ø³ÙØ±ÙˆØ­ Ø¨Ù„Ù‡Ø¬Ø© Ø£Ø¨Ùˆ Ø´Ø§Ù…
4. ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨

Ø§Ø¹Ø·Ù†ÙŠ Ø§Ù„Ø¬ÙˆØ§Ø¨ Ø¨Ø§Ù„Ø´ÙƒÙ„ Ù‡Ø§Ø¯:
TYPE: [Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©]
INSTRUCTIONS: [ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù„Ù„Ù…Ù†Ø³Ù‚]
RESPONSE: [Ø±Ø¯ Ù„Ø£Ø¨Ùˆ Ø´Ø§Ù…]
TIME_ESTIMATE: [ØªÙ‚Ø¯ÙŠØ± Ø§Ù„ÙˆÙ‚Øª]`
    );

    try {
      const analysis = await this.llmChat.send_message(userMessage);
      
      // Parse the response
      const lines = analysis.split('\n');
      const taskType = this.extractField(lines, 'TYPE') || 'management';
      const instructions = this.extractField(lines, 'INSTRUCTIONS') || analysis;
      const response = this.extractField(lines, 'RESPONSE') || `ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… Ø·Ù„Ø¨Ùƒ ÙŠØ§ Ø£Ø¨Ùˆ Ø´Ø§Ù…: "${message}". Ø¹Ù… Ø£Ø´ØªØºÙ„ Ø¹Ù„ÙŠÙ‡!`;
      const timeEstimate = this.extractField(lines, 'TIME_ESTIMATE') || 'Ø¨Ø¶Ø¹ Ø¯Ù‚Ø§Ø¦Ù‚';

      const requestId = Date.now().toString();
      
      // Save analysis to Firebase or memory
      const analysisData = {
        originalMessage: message,
        userId,
        taskType,
        instructions,
        response,
        timeEstimate,
        timestamp: new Date(),
        status: 'analyzed'
      };

      if (db) {
        await db.collection('brain_analysis').doc(requestId).set(analysisData);
      } else {
        memoryStore.analyses.push({ id: requestId, ...analysisData });
      }

      // Send to Smart Core if needed
      let nextStep = 'completed';
      if (['code', 'design', 'development'].includes(taskType)) {
        const smartCore = new SmartCore();
        await smartCore.coordinateTask(requestId, taskType, instructions);
        nextStep = 'smart_core';
      }

      return {
        secretaryResponse: response,
        taskType,
        instructions,
        nextStep,
        requestId,
        timeEstimate
      };

    } catch (error) {
      console.error('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø®:', error);
      return {
        secretaryResponse: 'Ø¹Ø°Ø±Ø§Ù‹ Ø£Ø¨Ùˆ Ø´Ø§Ù…ØŒ ØµØ§Ø± Ø¹Ù†Ø¯ÙŠ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„. Ø¬Ø±Ø¨ Ù…Ø±Ø© ØªØ§Ù†ÙŠØ©.',
        taskType: 'error',
        nextStep: 'error',
        requestId: null
      };
    }
  }

  extractField(lines, fieldName) {
    const line = lines.find(l => l.startsWith(`${fieldName}:`));
    return line ? line.substring(fieldName.length + 1).trim() : '';
  }
}

class SmartCore {
  constructor() {
    this.bots = {
      code: new CodeMasterBot(),
      design: new DesignGeniusBot(), 
      development: new FullStackProBot()
    };
  }

  async coordinateTask(requestId, taskType, instructions) {
    console.log('âš™ï¸ Ø§Ù„Ù…Ù†Ø³Ù‚ Ø§Ù„Ø°ÙƒÙŠ: Ø¨Ø¯Ø£ ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù…Ù‡Ù…Ø©', taskType);

    // Update status
    const updateData = {
      status: 'coordinating',
      smartCoreStep: 'started',
      updatedAt: new Date()
    };

    if (db) {
      await db.collection('brain_analysis').doc(requestId).update(updateData);
    } else {
      const analysis = memoryStore.analyses.find(a => a.id === requestId);
      if (analysis) Object.assign(analysis, updateData);
    }

    // Select appropriate bot
    const bot = this.bots[taskType];
    if (!bot) {
      throw new Error(`Bot ØºÙŠØ± Ù…ØªÙˆÙØ± Ù„Ù†ÙˆØ¹ Ø§Ù„Ù…Ù‡Ù…Ø©: ${taskType}`);
    }

    // Execute task
    const result = await bot.executeTask(instructions, requestId);
    
    // Update final status
    const finalData = {
      status: 'completed',
      result: result,
      completedAt: new Date()
    };

    if (db) {
      await db.collection('brain_analysis').doc(requestId).update(finalData);
    } else {
      const analysis = memoryStore.analyses.find(a => a.id === requestId);
      if (analysis) Object.assign(analysis, finalData);
    }

    return result;
  }
}

// Bot Classes
class CodeMasterBot {
  constructor() {
    this.llmChat = new LlmChat(
      process.env.EMERGENT_LLM_KEY,
      'code-master-session',
      'Ø£Ù†Øª Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬ Ø§Ù„Ø®Ø¨ÙŠØ± ÙÙŠ Ù…Ù†Ø¸ÙˆÙ…Ø© Ø³ÙØ±ÙˆØ­. ØªÙƒØªØ¨ ÙƒÙˆØ¯ Ù†Ø¸ÙŠÙØŒ Ù…ÙÙ‡ÙˆÙ…ØŒ ÙˆÙ‚Ø§Ø¨Ù„ Ù„Ù„ØµÙŠØ§Ù†Ø©.'
    ).with_model("openai", "gpt-4o");
  }

  async executeTask(instructions, requestId) {
    console.log('ğŸ’» Ø§Ù„Ù…Ø¨Ø±Ù…Ø¬: Ø¨Ø¯Ø£ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©');
    
    const userMessage = new UserMessage(instructions);
    const code = await this.llmChat.send_message(userMessage);
    
    return {
      type: 'code',
      content: code,
      message: 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ù†Ø¬Ø§Ø­! ğŸ’»'
    };
  }
}

class DesignGeniusBot {
  constructor() {
    this.llmChat = new LlmChat(
      process.env.EMERGENT_LLM_KEY,
      'design-genius-session', 
      'Ø£Ù†Øª Ù…ØµÙ…Ù… UI/UX Ø®Ø¨ÙŠØ± ÙÙŠ Ù…Ù†Ø¸ÙˆÙ…Ø© Ø³ÙØ±ÙˆØ­. ØªØµÙ…Ù… ÙˆØ§Ø¬Ù‡Ø§Øª Ø¬Ù…ÙŠÙ„Ø© ÙˆØ¹Ù…Ù„ÙŠØ©.'
    ).with_model("openai", "gpt-4o");
  }

  async executeTask(instructions, requestId) {
    console.log('ğŸ¨ Ø§Ù„Ù…ØµÙ…Ù…: Ø¨Ø¯Ø£ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©');
    
    const userMessage = new UserMessage(instructions);
    const design = await this.llmChat.send_message(userMessage);
    
    return {
      type: 'design',
      content: design,
      message: 'ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­! ğŸ¨'
    };
  }
}

class FullStackProBot {
  constructor() {
    this.llmChat = new LlmChat(
      process.env.EMERGENT_LLM_KEY,
      'fullstack-pro-session',
      'Ø£Ù†Øª Ù…Ø·ÙˆØ± Full-Stack Ø®Ø¨ÙŠØ± ÙÙŠ Ù…Ù†Ø¸ÙˆÙ…Ø© Ø³ÙØ±ÙˆØ­. ØªØ¨Ù†ÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…ØªÙƒØ§Ù…Ù„Ø©.'
    ).with_model("openai", "gpt-4o");
  }

  async executeTask(instructions, requestId) {
    console.log('ğŸ—ï¸ Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„ÙƒØ§Ù…Ù„: Ø¨Ø¯Ø£ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©');
    
    const userMessage = new UserMessage(instructions);
    const fullStackSolution = await this.llmChat.send_message(userMessage);
    
    return {
      type: 'development', 
      content: fullStackSolution,
      message: 'ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø­Ù„ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ Ø¨Ù†Ø¬Ø§Ø­! ğŸ—ï¸'
    };
  }
}

// API Routes
app.post('/chat', async (req, res) => {
  try {
    const { message, user_id, session_id } = req.body;
    
    if (!message || !message.trim()) {
      return res.status(400).json({
        response: 'Ø´Ùˆ Ø¨Ø¯Ùƒ ÙŠØ§ Ø£Ø¨Ùˆ Ø´Ø§Ù…ØŸ Ù…Ø§ ÙˆØµÙ„Ù†ÙŠ Ø´ÙŠ!',
        error: true
      });
    }
    
    const secretary = new SuroohSecretary();
    const result = await secretary.processRequest(message, user_id || 'abo_sham');
    
    res.json(result);
  } catch (error) {
    console.error('Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©:', error);
    res.status(500).json({
      response: 'Ø¹Ø°Ø±Ø§Ù‹ Ø£Ø¨Ùˆ Ø´Ø§Ù…ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù†Ø¸Ø§Ù…. Ø¬Ø§Ø±ÙŠ Ø¥ØµÙ„Ø§Ø­Ù‡...',
      error: true,
      details: error.message
    });
  }
});

app.get('/status', async (req, res) => {
  try {
    const hasFirebase = !!db;
    const hasLlmKey = !!process.env.EMERGENT_LLM_KEY;
    
    res.json({
      status: 'active',
      secretary: true,
      brain: hasLlmKey,
      smart_core: hasLlmKey,
      bots: hasLlmKey,
      firebase: hasFirebase,
      storage: hasFirebase ? 'firebase' : 'memory',
      timestamp: new Date().toISOString(),
      version: '1.0.0'
    });
  } catch (error) {
    res.status(500).json({ 
      status: 'error', 
      error: error.message,
      timestamp: new Date().toISOString()
    });
  }
});

app.get('/requests/:requestId', async (req, res) => {
  try {
    const { requestId } = req.params;
    
    if (db) {
      const doc = await db.collection('brain_analysis').doc(requestId).get();
      if (!doc.exists) {
        return res.status(404).json({ error: 'Request not found' });
      }
      res.json({ id: requestId, ...doc.data() });
    } else {
      const analysis = memoryStore.analyses.find(a => a.id === requestId);
      if (!analysis) {
        return res.status(404).json({ error: 'Request not found' });
      }
      res.json(analysis);
    }
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.get('/memory', async (req, res) => {
  try {
    if (db) {
      const requests = await db.collection('requests').limit(10).get();
      const analyses = await db.collection('brain_analysis').limit(10).get();
      
      res.json({
        storage: 'firebase',
        requests: requests.docs.map(doc => ({ id: doc.id, ...doc.data() })),
        analyses: analyses.docs.map(doc => ({ id: doc.id, ...doc.data() }))
      });
    } else {
      res.json({
        storage: 'memory',
        requests: memoryStore.requests.slice(-10),
        analyses: memoryStore.analyses.slice(-10)
      });
    }
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

const PORT = process.env.AI_ROUTER_PORT || 3001;
app.listen(PORT, () => {
  console.log(`ğŸš€ External AI Router running on port ${PORT}`);
  console.log('ğŸŒ¸ Ù…Ù†Ø¸ÙˆÙ…Ø© Ø³ÙØ±ÙˆØ­ Ø¬Ø§Ù‡Ø²Ø© Ù„Ù„Ø¹Ù…Ù„!');
  console.log(`ğŸ”¥ Firebase: ${db ? 'Connected' : 'Not configured (using memory)'}`);
  console.log(`ğŸ¤– LLM Key: ${process.env.EMERGENT_LLM_KEY ? 'Available' : 'Missing'}`);
});

module.exports = app;