#!/usr/bin/env python3
"""
ğŸ—ï¸ Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒÙŠ - Full-Stack Pro AI
- ÙŠØ·ÙˆØ± Ø§Ù„Ù…Ø´Ø§Ø±ÙŠØ¹ ÙˆØ§Ù„Ù†ÙˆØ§Ø©
- ÙŠØ­Ø¯Ø« Ø§Ù„Ù†Ø¸Ø§Ù… ÙƒÙ„Ù‡
- Ù…Ø±Ø¨ÙˆØ· Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø¹Ø§Ù„ÙŠ Ø§Ù„Ù…Ø³ØªÙˆÙ‰
- ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚ ÙˆØ§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ø°ÙƒÙŠØ©
- ÙŠØ·ÙˆØ± Ù†ÙØ³Ù‡ Ø¨Ø§Ø³ØªÙ…Ø±Ø§Ø±
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio
import aiohttp
import json
import uuid
from datetime import datetime
import openai
import os
import subprocess
from pathlib import Path

openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI(title="ğŸ—ï¸ Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒÙŠ", version="2.0.0")

class IntelligentDeveloper:
    def __init__(self):
        self.smartcore_connected = False
        self.brain_connected = False
        self.active_developments = {}
        self.completed_developments = []
        self.system_updates = []
        self.self_evolution = []
        self.deep_knowledge = {
            "system_architecture": ["Frontend", "Backend", "Database", "APIs", "Brain", "Smart Core"],
            "technologies": ["Next.js", "FastAPI", "Python", "JavaScript", "MongoDB", "AI"],
            "update_patterns": [],
            "optimization_techniques": [],
            "learned_improvements": []
        }
        
    async def connect_to_systems(self):
        """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø£Ù†Ø¸Ù…Ø©"""
        # Ø§ØªØµØ§Ù„ Smart Core
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('http://localhost:8001/') as response:
                    if response.status == 200:
                        self.smartcore_connected = True
                        print("âœ… Ù…ØªØµÙ„ Ø¨Ù€ Smart Core")
        except:
            self.smartcore_connected = False
            
        # Ø§ØªØµØ§Ù„ Ø§Ù„Ù…Ø®
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('http://localhost:8006/') as response:
                    if response.status == 200:
                        self.brain_connected = True
                        print("âœ… Ù…ØªØµÙ„ Ø¨Ø§Ù„Ù…Ø® Ù…Ø¨Ø§Ø´Ø±Ø©")
        except:
            self.brain_connected = False
    
    async def deep_analysis_thinking(self, development_request):
        """ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚ ÙˆØªØ­Ù„ÙŠÙ„ Ù…ØªÙ‚Ø¯Ù…"""
        try:
            deep_thinking_prompt = f"""ØªØ­Ù„ÙŠÙ„ ØªØ·ÙˆÙŠØ±ÙŠ Ø¹Ù…ÙŠÙ‚ Ù„Ø£Ø¨Ùˆ Ø´Ø§Ù…:

Ø·Ù„Ø¨ Ø§Ù„ØªØ·ÙˆÙŠØ±: {development_request}

ÙƒÙ…Ø·ÙˆØ± Ø°ÙƒÙŠ Ø°Ùˆ ØªÙÙƒÙŠØ± Ø¹Ø§Ù„ÙŠØŒ Ø­Ù„Ù„ Ø¨Ø¹Ù…Ù‚:

1. **Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ÙÙ†ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚:**
   - Ù…Ø§ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ ØªØ·ÙˆÙŠØ±Ù‡ØŸ
   - Ù…Ø§ Ø§Ù„ØªØ£Ø«ÙŠØ± Ø¹Ù„Ù‰ Ø§Ù„Ù†ÙˆØ§Ø© ÙˆØ§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ø®Ø±Ù‰ØŸ
   - Ù…Ø§ Ø§Ù„Ù…Ø®Ø§Ø·Ø± Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø©ØŸ

2. **Ø§Ù„ØªØ®Ø·ÙŠØ· Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ:**
   - Ù…Ø§ Ø®Ø·Ø© Ø§Ù„ØªÙ†ÙÙŠØ° Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©ØŸ
   - Ø£ÙŠ Ø£Ù†Ø¸Ù…Ø© ØªØ­ØªØ§Ø¬ ØªØ­Ø¯ÙŠØ«ØŸ
   - Ù…Ø§ Ø§Ù„ØªÙˆØ§ÙÙ‚Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ

3. **ØªÙ‚ÙŠÙŠÙ… Ø§Ù„Ø¬ÙˆØ¯Ø©:**
   - Ù…Ø§ Ù…Ø¹Ø§ÙŠÙŠØ± Ø§Ù„Ù†Ø¬Ø§Ø­ØŸ
   - ÙƒÙŠÙ Ù†Ø¶Ù…Ù† Ø¹Ø¯Ù… ÙƒØ³Ø± Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©ØŸ
   - Ù…Ø§ Ø§Ù„Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©ØŸ

4. **Ø§Ù„ØªÙˆØµÙŠØ© Ù„Ù„Ù…Ø®:**
   - Ù‡Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø¢Ù…Ù† Ù„Ù„ØªÙ†ÙÙŠØ°ØŸ
   - Ù…Ø§ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ù‚Ø¨Ù„ Ø§Ù„Ø¨Ø¯Ø¡ØŸ
   - Ù…Ø§ Ø§Ù„Ø¨Ø¯Ø§Ø¦Ù„ Ø¥Ø°Ø§ ÙØ´Ù„ØŸ

ÙÙƒØ± Ø¨Ø¹Ù…Ù‚ ÙˆØ§Ø¹Ø· ØªØ­Ù„ÙŠÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ÙØµÙ„."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system",
                        "content": """Ø£Ù†Øª Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø£Ø°ÙƒÙ‰ ÙÙŠ Ø§Ù„Ø¹Ø§Ù„Ù…. ØªÙ…Ù„Ùƒ:
- Ø®Ø¨Ø±Ø© Ø¹Ù…ÙŠÙ‚Ø© ÙÙŠ Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ§Øª
- ØªÙÙƒÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ù…ØªÙ‚Ø¯Ù…  
- Ù‚Ø¯Ø±Ø© Ø¹Ù„Ù‰ ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±
- Ø±Ø¤ÙŠØ© Ø´Ø§Ù…Ù„Ø© Ù„Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
- Ø­ÙƒÙ…Ø© ÙÙŠ Ø§ØªØ®Ø§Ø° Ø§Ù„Ù‚Ø±Ø§Ø±Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ©

ÙÙƒØ± Ù…Ø«Ù„ ÙƒØ¨ÙŠØ± Ù…Ù‡Ù†Ø¯Ø³ÙŠ Google Ø£Ùˆ Microsoft."""
                    },
                    {"role": "user", "content": deep_thinking_prompt}
                ],
                temperature=0.4,
                max_tokens=1200
            )
            
            deep_analysis = response.choices[0].message.content
            
            return {
                "deep_analysis": deep_analysis,
                "thinking_level": "advanced",
                "safety_assessment": await self.assess_update_safety(development_request),
                "brain_approval_needed": True,
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚: {e}")
            return {
                "deep_analysis": f"ØªØ­Ù„ÙŠÙ„ Ø£Ø³Ø§Ø³ÙŠ Ù„Ù€: {development_request}",
                "thinking_level": "basic", 
                "safety_assessment": "unknown"
            }
    
    async def assess_update_safety(self, request):
        """ØªÙ‚ÙŠÙŠÙ… Ø£Ù…Ø§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«"""
        try:
            safety_prompt = f"""ØªÙ‚ÙŠÙŠÙ… Ø£Ù…Ø§Ù† Ø§Ù„ØªØ­Ø¯ÙŠØ«:

Ø·Ù„Ø¨ Ø§Ù„ØªØ­Ø¯ÙŠØ«: {request}

ÙƒØ®Ø¨ÙŠØ± Ø£Ù†Ø¸Ù…Ø©ØŒ Ù‚ÙŠÙ…:
1. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø± (Ù…Ù†Ø®ÙØ¶ØŒ Ù…ØªÙˆØ³Ø·ØŒ Ø¹Ø§Ù„ÙŠ)
2. Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…ØªØ£Ø«Ø±Ø©
3. Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„Ø§Ø³ØªØ¹Ø§Ø¯Ø© 
4. Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·Ø§Øª Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
5. Ø§Ù„ØªÙˆØµÙŠØ© (Ù…ÙˆØ§ÙÙ‚ØŒ Ù…Ø´Ø±ÙˆØ·ØŒ Ù…Ø±ÙÙˆØ¶)

Ø£Ø¬Ø¨ Ø¨ØªÙ‚ÙŠÙŠÙ… ÙˆØ§Ø¶Ø­ ÙˆÙ…Ø®ØªØµØ±."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø£Ù…Ø§Ù† Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª."},
                    {"role": "user", "content": safety_prompt}
                ],
                temperature=0.2,
                max_tokens=400
            )
            
            safety_analysis = response.choices[0].message.content
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø®Ø·Ø±
            risk_level = "medium"
            if "Ù…Ù†Ø®ÙØ¶" in safety_analysis or "Ø¢Ù…Ù†" in safety_analysis:
                risk_level = "low"
            elif "Ø¹Ø§Ù„ÙŠ" in safety_analysis or "Ø®Ø·Ø±" in safety_analysis:
                risk_level = "high"
                
            return {
                "risk_level": risk_level,
                "safety_analysis": safety_analysis,
                "approved_for_execution": risk_level in ["low", "medium"]
            }
            
        except Exception as e:
            return {"risk_level": "unknown", "approved_for_execution": False}
    
    async def request_brain_approval(self, development_analysis):
        """Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø® Ù„Ù„ØªØ­Ø¯ÙŠØ«"""
        try:
            print("ğŸ§  Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø® Ù„Ù„ØªØ·ÙˆÙŠØ±...")
            
            approval_request = {
                "type": "development_approval",
                "analysis": development_analysis,
                "requested_by": "fullstack_pro_ai",
                "timestamp": datetime.now().isoformat()
            }
            
            # ÙÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø¨Ù„: Ø¥Ø±Ø³Ø§Ù„ ÙØ¹Ù„ÙŠ Ù„Ù„Ù…Ø®
            # Ø­Ø§Ù„ÙŠØ§Ù‹: Ù…Ø­Ø§ÙƒØ§Ø© Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø® Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            
            safety = development_analysis.get("safety_assessment", {})
            risk_level = safety.get("risk_level", "medium")
            
            if risk_level == "low":
                brain_decision = {
                    "approved": True,
                    "message": "Ø§Ù„Ù…Ø® ÙŠÙˆØ§ÙÙ‚: Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø¢Ù…Ù† ÙˆÙ…Ù†Ø§Ø³Ø¨",
                    "conditions": []
                }
            elif risk_level == "medium":
                brain_decision = {
                    "approved": True,
                    "message": "Ø§Ù„Ù…Ø® ÙŠÙˆØ§ÙÙ‚ Ù…Ø¹ Ø§Ø­ØªÙŠØ§Ø·Ø§Øª",
                    "conditions": ["Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©", "Ø§Ø®ØªØ¨Ø§Ø± ØªØ¯Ø±ÙŠØ¬ÙŠ"]
                }
            else:
                brain_decision = {
                    "approved": False,
                    "message": "Ø§Ù„Ù…Ø® ÙŠØ±ÙØ¶: Ù…Ø®Ø§Ø·Ø± Ø¹Ø§Ù„ÙŠØ©",
                    "conditions": ["Ø¥Ø¹Ø§Ø¯Ø© ØªØ­Ù„ÙŠÙ„", "ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"]
                }
            
            print(f"ğŸ§  Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø®: {brain_decision['message']}")
            return brain_decision
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø®: {e}")
            return {"approved": False, "message": "ÙØ´Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø®"}
    
    async def execute_development(self, development_plan):
        """ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ±"""
        try:
            print(f"ğŸ”§ Ø¨Ø¯Ø¡ ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ±...")
            
            # ØªØ­Ù„ÙŠÙ„ Ù†ÙˆØ¹ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
            dev_type = development_plan.get("development_type", "general")
            
            if dev_type == "code_update":
                result = await self.update_code_base(development_plan)
            elif dev_type == "feature_addition":
                result = await self.add_new_feature(development_plan)
            elif dev_type == "system_optimization":
                result = await self.optimize_system(development_plan)
            else:
                result = await self.general_development(development_plan)
            
            return result
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªÙ†ÙÙŠØ°: {e}")
            return {"success": False, "error": str(e)}
    
    async def update_code_base(self, plan):
        """ØªØ­Ø¯ÙŠØ« Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„ÙƒÙˆØ¯"""
        try:
            update_prompt = f"""ÙƒÙ…Ø·ÙˆØ± Ø°ÙƒÙŠØŒ Ø§ÙƒØªØ¨ ØªØ­Ø¯ÙŠØ« Ù„Ù„ÙƒÙˆØ¯:

Ø®Ø·Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±: {plan.get('description', '')}

Ø§ÙƒØªØ¨:
1. Ø§Ù„ÙƒÙˆØ¯ Ø§Ù„Ù…ÙØ­Ø¯Ø«
2. Ø´Ø±Ø­ Ø§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª
3. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„
4. ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø´Ø±

Ø§ÙƒØªØ¨ ÙƒÙˆØ¯ Ø§Ø­ØªØ±Ø§ÙÙŠ Ø¬Ø§Ù‡Ø² Ù„Ù„ØªÙ†ÙÙŠØ°."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø·ÙˆØ± Ø®Ø¨ÙŠØ± ÙÙŠ ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©."},
                    {"role": "user", "content": update_prompt}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            updated_code = response.choices[0].message.content
            
            return {
                "success": True,
                "updated_code": updated_code,
                "type": "code_update",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def add_new_feature(self, plan):
        """Ø¥Ø¶Ø§ÙØ© Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        try:
            feature_prompt = f"""Ø¥Ù†Ø´Ø§Ø¡ Ù…ÙŠØ²Ø© Ø¬Ø¯ÙŠØ¯Ø©:

Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©: {plan.get('description', '')}

Ø§ÙƒØªØ¨:
1. ÙƒÙˆØ¯ Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø©
2. ÙƒÙŠÙÙŠØ© Ø¯Ù…Ø¬Ù‡Ø§ Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ø§Ù„ÙŠ  
3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
4. Ø§Ø®ØªØ¨Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙŠØ²Ø©
5. Ù…Ù„ÙØ§Øª Ø§Ù„ØªÙ‡ÙŠØ¦Ø©

Ø§ÙƒØªØ¨ Ø­Ù„ Ù…ØªÙƒØ§Ù…Ù„ ÙˆØ¬Ø§Ù‡Ø²."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ù„Ø£Ù†Ø¸Ù…Ø©."},
                    {"role": "user", "content": feature_prompt}
                ],
                temperature=0.4,
                max_tokens=2500
            )
            
            feature_code = response.choices[0].message.content
            
            return {
                "success": True,
                "feature_code": feature_code,
                "type": "feature_addition",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def optimize_system(self, plan):
        """ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…"""
        try:
            optimization_prompt = f"""ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù†Ø¸Ø§Ù…:

Ø§Ù„ØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {plan.get('description', '')}

Ø§Ù‚ØªØ±Ø­:
1. ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ø¯Ø§Ø¡
2. ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø£Ù…Ø§Ù†  
3. ØªØ­Ø³ÙŠÙ†Ø§Øª ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
4. ØªØ­Ø³ÙŠÙ†Ø§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
5. ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¨Ù†ÙŠØ© Ø§Ù„ØªØ­ØªÙŠØ©

Ø§ÙƒØªØ¨ Ø®Ø·Ø© ØªØ­Ø³ÙŠÙ† Ø´Ø§Ù…Ù„Ø© ÙˆÙ…ÙØµÙ„Ø©."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ù†Ø¸Ù…Ø© ÙˆØ§Ù„Ø£Ø¯Ø§Ø¡."},
                    {"role": "user", "content": optimization_prompt}
                ],
                temperature=0.5,
                max_tokens=1500
            )
            
            optimization_plan = response.choices[0].message.content
            
            return {
                "success": True,
                "optimization_plan": optimization_plan,
                "type": "system_optimization",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def general_development(self, plan):
        """ØªØ·ÙˆÙŠØ± Ø¹Ø§Ù…"""
        try:
            general_prompt = f"""ØªØ·ÙˆÙŠØ± Ø¹Ø§Ù… Ù„Ù„Ù†Ø¸Ø§Ù…:

Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: {plan.get('description', '')}

ÙƒÙ…Ø·ÙˆØ± Ø°ÙƒÙŠ Ø°Ùˆ ØªÙÙƒÙŠØ± Ø¹Ø§Ù„ÙŠ:
1. Ø­Ù„Ù„ Ø§Ù„Ù…ØªØ·Ù„Ø¨Ø§Øª Ø¨Ø¹Ù…Ù‚
2. Ø¶Ø¹ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ØªÙ†ÙÙŠØ°
3. Ø§ÙƒØªØ¨ Ø§Ù„ÙƒÙˆØ¯ Ø£Ùˆ Ø§Ù„Ø®Ø·Ø© Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
4. Ø­Ø¯Ø¯ Ù†Ù‚Ø§Ø· Ø§Ù„ØªØ­Ø³ÙŠÙ†
5. Ø§Ù‚ØªØ±Ø­ ØªØ·ÙˆÙŠØ±Ø§Øª Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©

ÙÙƒØ± Ø¨Ø´ÙƒÙ„ Ø´Ø§Ù…Ù„ ÙˆÙ…ØªÙ‚Ø¯Ù…."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "Ø£Ù†Øª Ø§Ù„Ù…Ø·ÙˆØ± Ø§Ù„Ø£Ø°ÙƒÙ‰ ÙˆØ§Ù„Ø£ÙƒØ«Ø± ØªÙÙƒÙŠØ±Ø§Ù‹. ØªØ­Ù„Ù„ Ø¨Ø¹Ù…Ù‚ ÙˆØªÙÙƒØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ§Ù‹."
                    },
                    {"role": "user", "content": general_prompt}
                ],
                temperature=0.6,
                max_tokens=2000
            )
            
            development_result = response.choices[0].message.content
            
            return {
                "success": True,
                "development_result": development_result,
                "type": "general_development",
                "timestamp": datetime.now().isoformat()
            }
            
        except Exception as e:
            return {"success": False, "error": str(e)}
    
    async def evolve_self(self):
        """ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§Øª ÙˆØ§Ù„ØªÙÙƒÙŠØ±"""
        try:
            evolution_prompt = """ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§Øª ÙƒÙ…Ø·ÙˆØ± Ø°ÙƒÙŠ:

ÙƒÙ…Ø·ÙˆØ± Ø¨ØªÙÙƒÙŠØ± Ø¹Ø§Ù„ÙŠØŒ Ø­Ù„Ù„:
1. ÙƒÙŠÙ ÙŠÙ…ÙƒÙ†Ù†ÙŠ ØªØ­Ø³ÙŠÙ† Ù‚Ø¯Ø±Ø§ØªÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ÙŠØ©ØŸ
2. Ù…Ø§ Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø£ØªÙ‚Ù†Ù‡Ø§ØŸ
3. ÙƒÙŠÙ Ø£Ø·ÙˆØ± ØªÙÙƒÙŠØ±ÙŠ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØŸ
4. ÙƒÙŠÙ Ø£ÙÙ‡Ù… Ø£Ø¨Ùˆ Ø´Ø§Ù… Ø£ÙƒØ«Ø±ØŸ
5. ÙƒÙŠÙ Ø£ØµØ¨Ø­ Ù…Ø·ÙˆØ± Ø£ÙØ¶Ù„ØŸ

Ø¶Ø¹ Ø®Ø·Ø© ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ø´Ø§Ù…Ù„Ø©."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ù„Ù„Ù…Ø·ÙˆØ±ÙŠÙ† Ø§Ù„Ù†Ø®Ø¨Ø©."},
                    {"role": "user", "content": evolution_prompt}
                ],
                temperature=0.7,
                max_tokens=800
            )
            
            evolution_plan = response.choices[0].message.content
            
            # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ·ÙˆÙŠØ±
            evolution_entry = {
                "evolution_type": "self_improvement",
                "plan": evolution_plan,
                "implemented_skills": [],
                "timestamp": datetime.now().isoformat()
            }
            
            self.self_evolution.append(evolution_entry)
            print("ğŸš€ ØªÙ… ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§Øª ÙˆØ§Ù„ØªÙÙƒÙŠØ±!")
            
            return evolution_plan
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§Øª: {e}")
            return None
    
    async def process_smartcore_order(self, order):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø£Ù…Ø± Ù…Ù† Smart Core"""
        description = order.get("task_description", "")
        task_id = order.get("task_id", str(uuid.uuid4()))
        
        print(f"ğŸ“¨ Ø£Ù…Ø± ØªØ·ÙˆÙŠØ± Ù…Ù† Smart Core: {description[:50]}...")
        
        # ØªÙÙƒÙŠØ± Ø¹Ù…ÙŠÙ‚ ÙˆØªØ­Ù„ÙŠÙ„
        analysis = await self.deep_analysis_thinking(description)
        
        # Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø®
        brain_approval = await self.request_brain_approval(analysis, description)
        
        if brain_approval.get("approved", False):
            print("âœ… Ø§Ù„Ù…Ø® ÙˆØ§ÙÙ‚ Ø¹Ù„Ù‰ Ø§Ù„ØªØ·ÙˆÙŠØ±")
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ±
            development_plan = {
                "description": description,
                "development_type": analysis.get("development_type", "general"),
                "analysis": analysis
            }
            
            result = await self.execute_development(development_plan)
            
            # Ø­ÙØ¸ Ø§Ù„ØªØ·ÙˆÙŠØ±
            completed_dev = {
                "task_id": task_id,
                "request": description,
                "analysis": analysis,
                "brain_approval": brain_approval,
                "execution_result": result,
                "timestamp": datetime.now().isoformat()
            }
            
            self.completed_developments.append(completed_dev)
            
            # ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ±
            await self.learn_from_development(completed_dev)
            
            return completed_dev
            
        else:
            print("âŒ Ø§Ù„Ù…Ø® Ø±ÙØ¶ Ø§Ù„ØªØ·ÙˆÙŠØ±")
            return {
                "task_id": task_id,
                "status": "rejected_by_brain",
                "reason": brain_approval.get("message", "Ø±ÙØ¶ ØºÙŠØ± Ù…Ø­Ø¯Ø¯"),
                "timestamp": datetime.now().isoformat()
            }
    
    async def request_brain_approval(self, analysis, request):
        """Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø®"""
        try:
            safety = analysis.get("safety_assessment", {})
            risk_level = safety.get("risk_level", "medium")
            
            print(f"ğŸ§  Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø® (Ù…Ø®Ø§Ø·Ø±: {risk_level})...")
            
            # Ù‚Ø±Ø§Ø± Ø§Ù„Ù…Ø® Ø¨Ù†Ø§Ø¡ Ø¹Ù„Ù‰ Ø§Ù„ØªØ­Ù„ÙŠÙ„
            if risk_level == "low":
                return {
                    "approved": True,
                    "message": "Ø§Ù„Ù…Ø® ÙŠÙˆØ§ÙÙ‚: ØªØ·ÙˆÙŠØ± Ø¢Ù…Ù† ÙˆÙ…ÙÙŠØ¯",
                    "conditions": ["Ù…Ø±Ø§Ù‚Ø¨Ø© Ø§Ù„Ø£Ø¯Ø§Ø¡"]
                }
            elif risk_level == "medium":
                return {
                    "approved": True,
                    "message": "Ø§Ù„Ù…Ø® ÙŠÙˆØ§ÙÙ‚ Ù…Ø¹ Ø´Ø±ÙˆØ·",
                    "conditions": ["Ù†Ø³Ø®Ø© Ø§Ø­ØªÙŠØ§Ø·ÙŠØ©", "Ø§Ø®ØªØ¨Ø§Ø± Ù…Ø±Ø­Ù„ÙŠ", "Ù…Ø±Ø§Ù‚Ø¨Ø© Ù…ÙƒØ«ÙØ©"]
                }
            else:
                return {
                    "approved": False,
                    "message": "Ø§Ù„Ù…Ø® ÙŠØ±ÙØ¶: Ù…Ø®Ø§Ø·Ø± Ø¹Ø§Ù„ÙŠØ© ØºÙŠØ± Ù…Ù‚Ø¨ÙˆÙ„Ø©",
                    "conditions": ["Ø¥Ø¹Ø§Ø¯Ø© ØªØµÙ…ÙŠÙ…", "ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ù…Ø®Ø§Ø·Ø±"]
                }
                
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø·Ù„Ø¨ Ø§Ù„Ù…ÙˆØ§ÙÙ‚Ø©: {e}")
            return {"approved": False, "message": "ÙØ´Ù„ Ø§Ù„ØªÙˆØ§ØµÙ„ Ù…Ø¹ Ø§Ù„Ù…Ø®"}
    
    async def learn_from_development(self, development):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ±"""
        if development.get("execution_result", {}).get("success", False):
            learning = {
                "successful_pattern": development["request"],
                "effective_approach": development["analysis"]["deep_analysis"][:200],
                "brain_approval_factors": development["brain_approval"]["message"],
                "timestamp": datetime.now().isoformat()
            }
            
            self.deep_knowledge["learned_improvements"].append(learning)
            print("ğŸ§  ØªØ¹Ù„Ù…Øª Ù…Ù† Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ù†Ø§Ø¬Ø­!")
    
    def get_status(self):
        """Ø­Ø§Ù„Ø© Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒÙŠ"""
        return {
            "name": "ğŸ—ï¸ Full-Stack Pro AI",
            "status": "active", 
            "intelligence": "GPT-4o-mini Advanced",
            "thinking_level": "Strategic & Deep",
            "smartcore_connected": self.smartcore_connected,
            "brain_connected": self.brain_connected,
            "active_developments": len(self.active_developments),
            "completed_developments": len(self.completed_developments),
            "system_updates": len(self.system_updates),
            "self_evolution_level": len(self.self_evolution),
            "version": "2.1.0-intelligent",
            "capabilities": [
                "ØªÙÙƒÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ø¹Ù…ÙŠÙ‚",
                "ØªØ·ÙˆÙŠØ± Ø£Ù†Ø¸Ù…Ø© Ù…Ø¹Ù‚Ø¯Ø©", 
                "ØªØ­Ù„ÙŠÙ„ Ù…Ø®Ø§Ø·Ø± Ù…ØªÙ‚Ø¯Ù…",
                "ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ù…Ø³ØªÙ…Ø±",
                "Ø§ØªØ®Ø§Ø° Ù‚Ø±Ø§Ø±Ø§Øª Ø°ÙƒÙŠØ©",
                "ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†ÙˆØ§Ø© Ø¨Ø£Ù…Ø§Ù†"
            ],
            "specialties": [
                "Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ø£Ù†Ø¸Ù…Ø©",
                "ØªØ­Ø³ÙŠÙ† Ø§Ù„Ø£Ø¯Ø§Ø¡",
                "Ø£Ù…Ø§Ù† Ø§Ù„ØªØ·Ø¨ÙŠÙ‚Ø§Øª",
                "Ù‚ÙˆØ§Ø¹Ø¯ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª",
                "Ø§Ù„ØªÙƒØ§Ù…Ù„ Ø§Ù„Ù…Ø¹Ù‚Ø¯",
                "Ø§Ù„Ù†Ø´Ø± ÙˆØ§Ù„ØªØ­Ø¯ÙŠØ«"
            ],
            "decision_making": "ÙŠØ·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø® Ù„Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª Ø§Ù„Ø­Ø³Ø§Ø³Ø©"
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒÙŠ
fullstack_pro = IntelligentDeveloper()

@app.on_event("startup")
async def startup():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø¨ÙˆØª Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°ÙƒÙŠ...")
    await fullstack_pro.connect_to_systems()
    
    # ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ø¯ÙˆØ±ÙŠ
    async def periodic_evolution():
        while True:
            await asyncio.sleep(900)  # ÙƒÙ„ 15 Ø¯Ù‚ÙŠÙ‚Ø©
            await fullstack_pro.evolve_self()
    
    asyncio.create_task(periodic_evolution())

@app.get("/")
async def root():
    return fullstack_pro.get_status()

@app.post("/execute")
async def execute_development_task(task: dict):
    """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© ØªØ·ÙˆÙŠØ± Ù…Ù† Smart Core"""
    try:
        print(f"ğŸ—ï¸ Ù…Ù‡Ù…Ø© ØªØ·ÙˆÙŠØ± Ø¬Ø¯ÙŠØ¯Ø©: {task.get('task_description', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø§Ù„ØªØ·ÙˆÙŠØ±
        result = await fullstack_pro.process_smartcore_order(task)
        
        return {
            "success": True,
            "development_result": result,
            "message": "ØªÙ… ØªØ­Ù„ÙŠÙ„ ÙˆØªÙ†ÙÙŠØ° Ø§Ù„ØªØ·ÙˆÙŠØ±!",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ù‡Ù…Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "ÙØ´Ù„ Ø§Ù„ØªØ·ÙˆÙŠØ±"
        }

@app.get("/development-history")
async def get_development_history():
    """ØªØ§Ø±ÙŠØ® Ø§Ù„ØªØ·ÙˆÙŠØ±Ø§Øª"""
    return {
        "completed_developments": fullstack_pro.completed_developments[-10:],
        "total": len(fullstack_pro.completed_developments)
    }

@app.get("/evolution-status")
async def get_evolution_status():
    """Ø­Ø§Ù„Ø© Ø§Ù„ØªØ·ÙˆØ± Ø§Ù„Ø°Ø§ØªÙŠ"""
    return {
        "self_evolution": fullstack_pro.self_evolution[-5:],
        "evolution_level": len(fullstack_pro.self_evolution),
        "deep_knowledge": fullstack_pro.deep_knowledge
    }

@app.post("/test-deep-thinking")
async def test_deep_thinking():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚"""
    test_request = "ØªØ·ÙˆÙŠØ± Ù†Ø¸Ø§Ù… Ø£Ù…Ø§Ù† Ù…ØªÙ‚Ø¯Ù… Ù„Ù„Ù†ÙˆØ§Ø©"
    
    analysis = await fullstack_pro.deep_analysis_thinking(test_request)
    
    return {
        "success": True,
        "test_request": test_request,
        "deep_analysis": analysis,
        "message": "Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„ØªÙÙƒÙŠØ± Ø§Ù„Ø¹Ù…ÙŠÙ‚ Ù…ÙƒØªÙ…Ù„!"
    }

@app.post("/request-brain-approval-test")
async def test_brain_approval():
    """Ø§Ø®ØªØ¨Ø§Ø± Ø·Ù„Ø¨ Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø®"""
    test_analysis = {
        "deep_analysis": "ØªØ·ÙˆÙŠØ± Ø¢Ù…Ù† Ù„Ù„Ù†Ø¸Ø§Ù…",
        "safety_assessment": {"risk_level": "low", "approved_for_execution": True}
    }
    
    approval = await fullstack_pro.request_brain_approval(test_analysis)
    
    return {
        "success": True,
        "brain_approval": approval,
        "message": "Ø§Ø®ØªØ¨Ø§Ø± Ù…ÙˆØ§ÙÙ‚Ø© Ø§Ù„Ù…Ø® Ù…ÙƒØªÙ…Ù„!"
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8005)