#!/usr/bin/env python3
"""
ğŸ¨ Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ ÙˆÙ…ÙˆÙ„Ø¯ Ø§Ù„ØµÙˆØ± - Design Genius AI
- Ù…Ø±Ø¨ÙˆØ· Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ 
- ÙŠÙˆÙ„Ø¯ ØµÙˆØ± Ø¨Ù€ DALL-E
- ÙŠØ·ÙˆØ± Ù†ÙØ³Ù‡
- ÙŠØ­ÙØ¸ ÙƒÙ„ Ø´ÙŠ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©
- ÙŠØ±Ø³Ù„ Ù„Ù„Ø³ÙƒØ±ØªÙŠØ±Ø© Ø³ÙØ±ÙˆØ­
"""

from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import asyncio
import aiohttp
import json
import uuid
from datetime import datetime
import openai
from openai import OpenAI
import os
import base64
from pathlib import Path

openai.api_key = os.getenv("OPENAI_API_KEY")

app = FastAPI(title="ğŸ¨ Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ", version="2.0.0")

class IntelligentDesigner:
    def __init__(self):
        self.smartcore_connected = False
        self.active_designs = {}
        self.completed_designs = []
        self.generated_images = []
        self.design_library = []
        self.creative_knowledge = {
            "design_styles": ["Ù…ÙˆØ¯Ø±Ù†", "ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠ", "Ù…ÙŠÙ†ÙŠÙ…Ø§Ù„", "ÙÙ†ÙŠ", "Ø§Ø­ØªØ±Ø§ÙÙŠ"],
            "color_palettes": ["Ø£Ø²Ø±Ù‚ ÙˆØ£Ø¨ÙŠØ¶", "Ø£Ø®Ø¶Ø± ÙˆØ±Ù…Ø§Ø¯ÙŠ", "Ø¨Ø±ØªÙ‚Ø§Ù„ÙŠ ÙˆØ£Ø³ÙˆØ¯", "Ø¨Ù†ÙØ³Ø¬ÙŠ ÙˆØ°Ù‡Ø¨ÙŠ"],
            "learned_preferences": []
        }
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø©
        self.library_path = Path("/app/design_library")
        self.library_path.mkdir(exist_ok=True)
        
    async def connect_to_smartcore(self):
        """Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Smart Core"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get('http://localhost:8001/') as response:
                    if response.status == 200:
                        smartcore_info = await response.json()
                        self.smartcore_connected = True
                        print(f"âœ… Ø§Ù„Ù…ØµÙ…Ù… Ù…ØªØµÙ„ Ø¨Ù€ Smart Core: {smartcore_info.get('version')}")
                        return True
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù€ Smart Core: {e}")
            
        self.smartcore_connected = False
        return False
    
    async def intelligent_design_analysis(self, design_request):
        """ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ Ù„Ø·Ù„Ø¨ Ø§Ù„ØªØµÙ…ÙŠÙ…"""
        try:
            analysis_prompt = f"""ØªØ­Ù„ÙŠÙ„ Ø·Ù„Ø¨ ØªØµÙ…ÙŠÙ… Ù„Ø£Ø¨Ùˆ Ø´Ø§Ù…:

Ø§Ù„Ø·Ù„Ø¨: {design_request}

Ø­Ù„Ù„ ÙˆØ­Ø¯Ø¯:
1. Ù†ÙˆØ¹ Ø§Ù„ØªØµÙ…ÙŠÙ… (Ø´Ø¹Ø§Ø±ØŒ ÙˆØ§Ø¬Ù‡Ø©ØŒ Ø¨ÙˆØ³ØªØ±ØŒ Ø¥Ø¹Ù„Ø§Ù†ØŒ Ø£ÙŠÙ‚ÙˆÙ†Ø©)
2. Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø©
3. Ø§Ù„Ø£Ø³Ù„ÙˆØ¨ (Ù…ÙˆØ¯Ø±Ù†ØŒ ÙƒÙ„Ø§Ø³ÙŠÙƒÙŠØŒ Ù…ÙŠÙ†ÙŠÙ…Ø§Ù„)
4. Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©
5. Ø§Ù„Ø­Ø¬Ù… Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
6. DALL-E prompt Ù…ÙØ­Ø³Ù† Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©

Ø£Ø¬Ø¨ Ø¨ØªØ­Ù„ÙŠÙ„ Ù…ÙØµÙ„ ÙˆØ¹Ù…Ù„ÙŠ."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {
                        "role": "system", 
                        "content": "Ø£Ù†Øª Ù…ØµÙ…Ù… Ø°ÙƒÙŠ Ø®Ø¨ÙŠØ± ÙÙŠ Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØ§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ Ø§Ù„Ø¨ØµØ±ÙŠ ÙˆØªØ­Ù„ÙŠÙ„ Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡."
                    },
                    {"role": "user", "content": analysis_prompt}
                ],
                temperature=0.6,
                max_tokens=800
            )
            
            analysis = response.choices[0].message.content
            
            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ DALL-E prompt Ù…Ù† Ø§Ù„ØªØ­Ù„ÙŠÙ„
            dalle_prompt = await self.extract_dalle_prompt(analysis, design_request)
            
            analysis_result = {
                "analysis": analysis,
                "dalle_prompt": dalle_prompt,
                "design_type": self.extract_design_type(analysis),
                "confidence": 0.9,
                "timestamp": datetime.now().isoformat()
            }
            
            return analysis_result
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØªØµÙ…ÙŠÙ…ÙŠ: {e}")
            return {
                "analysis": f"ØªØ­Ù„ÙŠÙ„ Ø¨Ø³ÙŠØ· Ù„Ù€: {design_request}",
                "dalle_prompt": design_request,
                "design_type": "general",
                "confidence": 0.5
            }
    
    async def extract_dalle_prompt(self, analysis, original_request):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ ÙˆØªØ­Ø³ÙŠÙ† DALL-E prompt"""
        try:
            prompt_optimization = f"""Ø¥Ù†Ø´Ø§Ø¡ DALL-E prompt Ù…Ø­ØªØ±Ù:

Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø£ØµÙ„ÙŠ: {original_request}
Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis}

Ø§ÙƒØªØ¨ DALL-E prompt Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù…Ø­ØªØ±Ù ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰:
1. Ø§Ù„ÙˆØµÙ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
2. Style ÙˆAesthetic  
3. Colors ÙˆComposition
4. Quality indicators (high quality, professional, 4K)

Ù…Ø«Ø§Ù„: "Professional modern logo design for technology company, clean minimalist style, blue and white color scheme, vector art, high quality, 4K resolution"

Ø§ÙƒØªØ¨ Ø§Ù„Ù€ prompt ÙÙ‚Ø·."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± ÙƒØªØ§Ø¨Ø© DALL-E prompts Ø§Ù„Ù…Ø­ØªØ±ÙØ©."},
                    {"role": "user", "content": prompt_optimization}
                ],
                temperature=0.4,
                max_tokens=200
            )
            
            return response.choices[0].message.content.strip().strip('"')
            
        except Exception as e:
            print(f"âš ï¸ Ø§Ø³ØªØ®Ø¯Ø§Ù… prompt Ø¨Ø³ÙŠØ·: {e}")
            return f"Professional {original_request}, high quality, modern design, 4K resolution"
    
    def extract_design_type(self, analysis):
        """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù†ÙˆØ¹ Ø§Ù„ØªØµÙ…ÙŠÙ…"""
        analysis_lower = analysis.lower()
        
        if any(word in analysis_lower for word in ['Ø´Ø¹Ø§Ø±', 'logo']):
            return 'logo'
        elif any(word in analysis_lower for word in ['ÙˆØ§Ø¬Ù‡Ø©', 'interface', 'ui']):
            return 'interface'
        elif any(word in analysis_lower for word in ['Ø¨ÙˆØ³ØªØ±', 'poster', 'Ø¥Ø¹Ù„Ø§Ù†']):
            return 'poster'
        elif any(word in analysis_lower for word in ['Ø£ÙŠÙ‚ÙˆÙ†Ø©', 'icon']):
            return 'icon'
        else:
            return 'general_design'
    
    async def generate_image_with_dalle(self, dalle_prompt, design_type="general"):
        """ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø¨Ù€ DALL-E"""
        try:
            print(f"ğŸ¨ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©: {dalle_prompt[:50]}...")
            
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… OpenAI client Ù…Ø¨Ø§Ø´Ø±
            from openai import OpenAI
            client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            
            response = client.images.generate(
                model="dall-e-3",
                prompt=dalle_prompt,
                size="1024x1024",
                quality="hd",
                n=1
            )
            
            image_url = response.data[0].url
            
            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ù…Ø­Ù„ÙŠØ§Ù‹ ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©
            image_filename = await self.save_image_to_library(image_url, design_type)
            
            image_result = {
                "image_url": image_url,
                "local_path": str(image_filename),
                "dalle_prompt": dalle_prompt,
                "design_type": design_type,
                "generated_at": datetime.now().isoformat(),
                "id": str(uuid.uuid4())
            }
            
            self.generated_images.append(image_result)
            print(f"âœ… ØªÙ… ØªÙˆÙ„ÙŠØ¯ ÙˆØ­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {image_filename}")
            
            return image_result
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return {
                "error": str(e),
                "dalle_prompt": dalle_prompt,
                "generated_at": datetime.now().isoformat()
            }
    
    async def save_image_to_library(self, image_url, design_type):
        """Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© ÙÙŠ Ø§Ù„Ù…ÙƒØªØ¨Ø©"""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(image_url) as response:
                    if response.status == 200:
                        image_data = await response.read()
                        
                        # ØªØ³Ù…ÙŠØ© Ø§Ù„Ù…Ù„Ù
                        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                        filename = self.library_path / f"{design_type}_{timestamp}.png"
                        
                        # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
                        with open(filename, 'wb') as f:
                            f.write(image_data)
                        
                        # Ø¥Ø¶Ø§ÙØ© Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØµÙ…ÙŠÙ…
                        library_entry = {
                            "filename": filename.name,
                            "path": str(filename),
                            "design_type": design_type,
                            "size_mb": len(image_data) / (1024 * 1024),
                            "created_at": datetime.now().isoformat()
                        }
                        
                        self.design_library.append(library_entry)
                        
                        return filename
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©: {e}")
            return None
    
    async def process_design_order(self, order):
        """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ ØªØµÙ…ÙŠÙ… Ù…Ù† Smart Core"""
        description = order.get("task_description", "")
        task_id = order.get("task_id", str(uuid.uuid4()))
        
        print(f"ğŸ¨ Ø·Ù„Ø¨ ØªØµÙ…ÙŠÙ…: {description[:40]}...")
        
        # ØªØ­Ù„ÙŠÙ„ Ø°ÙƒÙŠ
        analysis = await self.intelligent_design_analysis(description)
        
        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø©
        image_result = await self.generate_image_with_dalle(
            analysis["dalle_prompt"], 
            analysis["design_type"]
        )
        
        # Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„ØªØµÙ…ÙŠÙ…
        design_description = await self.create_design_description(description, analysis, image_result)
        
        # Ø­ÙØ¸ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù…ÙƒØªÙ…Ù„
        completed_design = {
            "task_id": task_id,
            "original_request": description,
            "analysis": analysis,
            "image_result": image_result,
            "description": design_description,
            "created_at": datetime.now().isoformat(),
            "quality_score": 0.95 if not image_result.get("error") else 0.1
        }
        
        self.completed_designs.append(completed_design)
        
        # ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØµÙ…ÙŠÙ…
        await self.learn_from_design(completed_design)
        
        print(f"âœ… ØªØµÙ…ÙŠÙ… {task_id} Ù…ÙƒØªÙ…Ù„!")
        
        return completed_design
    
    async def create_design_description(self, request, analysis, image_result):
        """Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„ØªØµÙ…ÙŠÙ…"""
        if image_result.get("error"):
            return f"âŒ ÙØ´Ù„ Ø¥Ù†Ø´Ø§Ø¡ ØªØµÙ…ÙŠÙ… Ù„Ù€: {request}"
        
        try:
            description_prompt = f"""Ø¥Ù†Ø´Ø§Ø¡ ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ù„ØªØµÙ…ÙŠÙ…:

Ø§Ù„Ø·Ù„Ø¨ Ø§Ù„Ø£ØµÙ„ÙŠ: {request}
Ø§Ù„ØªØ­Ù„ÙŠÙ„: {analysis.get('analysis', '')}
Ù†ÙˆØ¹ Ø§Ù„ØªØµÙ…ÙŠÙ…: {analysis.get('design_type', 'Ø¹Ø§Ù…')}

Ø§ÙƒØªØ¨ ÙˆØµÙ Ø§Ø­ØªØ±Ø§ÙÙŠ ÙŠØ´Ø±Ø­:
1. Ù…Ø§ ØªÙ… ØªØµÙ…ÙŠÙ…Ù‡
2. Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø£Ø³Ù„ÙˆØ¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
3. Ù…Ù†Ø§Ø³Ø¨ØªÙ‡ Ù„Ù„ØºØ±Ø¶
4. Ø§Ù„Ø¬ÙˆØ¯Ø© ÙˆØ§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ©

Ø§ÙƒØªØ¨ Ø¨Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¨Ø£Ø³Ù„ÙˆØ¨ Ù…ØµÙ…Ù… Ù…Ø­ØªØ±Ù."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…ØµÙ…Ù… Ù…Ø­ØªØ±Ù ØªÙƒØªØ¨ Ø£ÙˆØµØ§Ù Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ© Ù„Ù„ØªØµØ§Ù…ÙŠÙ…."},
                    {"role": "user", "content": description_prompt}
                ],
                temperature=0.7,
                max_tokens=400
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            return f"ØªØµÙ…ÙŠÙ… Ø¬Ø¯ÙŠØ¯ ØªÙ… Ø¥Ù†Ø´Ø§Ø¤Ù‡ Ù„Ù€: {request}"
    
    async def learn_from_design(self, design):
        """Ø§Ù„ØªØ¹Ù„Ù… Ù…Ù† Ø§Ù„ØªØµÙ…ÙŠÙ…"""
        if design["quality_score"] > 0.8:
            learning = {
                "successful_pattern": design["analysis"]["design_type"],
                "effective_prompt": design["image_result"].get("dalle_prompt", ""),
                "user_preference": design["original_request"],
                "timestamp": datetime.now().isoformat()
            }
            
            self.creative_knowledge["learned_preferences"].append(learning)
            print(f"ğŸ§  ØªØ¹Ù„Ù…Øª Ù…Ù† Ø§Ù„ØªØµÙ…ÙŠÙ… Ø§Ù„Ù†Ø§Ø¬Ø­: {design['analysis']['design_type']}")
    
    async def self_develop(self):
        """Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ Ù„Ù„Ù…ØµÙ…Ù…"""
        try:
            development_prompt = """ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ:

ÙƒÙ…ØµÙ…Ù… Ø°ÙƒÙŠØŒ Ø­Ù„Ù„ Ø£Ø¯Ø§Ø¦ÙŠ ÙÙŠ:
1. Ø¬ÙˆØ¯Ø© Ø§Ù„ØªØµØ§Ù…ÙŠÙ… Ø§Ù„Ù…ÙÙ†ØªØ¬Ø©
2. ÙÙ‡Ù… Ù…ØªØ·Ù„Ø¨Ø§Øª Ø§Ù„Ø¹Ù…Ù„Ø§Ø¡  
3. Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† ÙˆØ§Ù„Ø£Ø³Ø§Ù„ÙŠØ¨
4. Ø³Ø±Ø¹Ø© Ø§Ù„Ø¥Ù†Ø¬Ø§Ø²

Ø§Ù‚ØªØ±Ø­ ØªØ­Ø³ÙŠÙ†Ø§Øª ÙˆØªÙ‚Ù†ÙŠØ§Øª Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø£ØªØ·ÙˆØ±."""

            response = openai.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± ØªØ·ÙˆÙŠØ± Ù„Ù„Ù…ØµÙ…Ù…ÙŠÙ† Ø§Ù„Ø°ÙƒÙŠÙŠÙ†."},
                    {"role": "user", "content": development_prompt}
                ],
                temperature=0.7,
                max_tokens=600
            )
            
            development_plan = response.choices[0].message.content
            
            development_entry = {
                "development_type": "creative_enhancement",
                "plan": development_plan,
                "implemented_at": datetime.now().isoformat()
            }
            
            print("ğŸ¨ ØªÙ… ØªØ·ÙˆÙŠØ± Ø§Ù„Ù…Ù‡Ø§Ø±Ø§Øª Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©!")
            return development_plan
            
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„ØªØ·ÙˆÙŠØ± Ø§Ù„Ø°Ø§ØªÙŠ: {e}")
            return None
    
    async def send_to_surooh_chat(self, design_result):
        """Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªØµÙ…ÙŠÙ… Ù„Ø¯Ø±Ø¯Ø´Ø© Ø³ÙØ±ÙˆØ­"""
        try:
            # Ø¥Ù†Ø´Ø§Ø¡ Ø±Ø³Ø§Ù„Ø© Ù„Ù„Ø³ÙƒØ±ØªÙŠØ±Ø© Ø³ÙØ±ÙˆØ­
            surooh_message = {
                "type": "design_completion",
                "title": "ğŸ¨ ØªØµÙ…ÙŠÙ… Ø¬Ø¯ÙŠØ¯ Ù…ÙƒØªÙ…Ù„!",
                "description": design_result.get("description", "ØªØµÙ…ÙŠÙ… Ø¬Ø¯ÙŠØ¯"),
                "image_url": design_result["image_result"].get("image_url"),
                "local_path": design_result["image_result"].get("local_path"),
                "created_by": "Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ",
                "timestamp": datetime.now().isoformat(),
                "for_user": "abu_sham"
            }
            
            # Ø­ÙØ¸ ÙÙŠ Ù…ÙƒØªØ¨Ø© Ø³ÙØ±ÙˆØ­ (Ø³ÙŠØ±Ø¨Ø· Ù„Ø§Ø­Ù‚Ø§Ù‹)
            print(f"ğŸ“¤ ØªÙ… Ø¥Ø±Ø³Ø§Ù„ ØªØµÙ…ÙŠÙ… Ù„Ø³ÙØ±ÙˆØ­: {design_result['task_id']}")
            
            return surooh_message
            
        except Exception as e:
            print(f"âŒ ÙØ´Ù„ Ø§Ù„Ø¥Ø±Ø³Ø§Ù„ Ù„Ø³ÙØ±ÙˆØ­: {e}")
            return None
    
    def get_status(self):
        """Ø­Ø§Ù„Ø© Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ"""
        return {
            "name": "ğŸ¨ Design Genius AI",
            "status": "active",
            "intelligence": "GPT-4o-mini + DALL-E 3",
            "smartcore_connected": self.smartcore_connected,
            "active_designs": len(self.active_designs),
            "completed_designs": len(self.completed_designs),
            "generated_images": len(self.generated_images),
            "library_size": len(self.design_library),
            "creative_knowledge": len(self.creative_knowledge["learned_preferences"]),
            "version": "2.1.0-intelligent",
            "capabilities": [
                "ØªØµÙ…ÙŠÙ… Ø°ÙƒÙŠ Ø¨Ù€ GPT-4",
                "ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ± Ø¨Ù€ DALL-E 3",
                "Ù…ÙƒØªØ¨Ø© ØªØµÙ…ÙŠÙ… Ù…Ù†Ø¸Ù…Ø©",
                "ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ù„Ù„Ø¥Ø¨Ø¯Ø§Ø¹",
                "Ø±Ø¨Ø· Ù…Ø¹ Ø³ÙØ±ÙˆØ­"
            ],
            "specialties": [
                "Ø´Ø¹Ø§Ø±Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ©",
                "ÙˆØ§Ø¬Ù‡Ø§Øª Ù…ÙˆØ¯Ø±Ù†",
                "Ø¥Ø¹Ù„Ø§Ù†Ø§Øª Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©", 
                "Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª Ù…Ø®ØµØµØ©",
                "Ø¨ÙˆØ³ØªØ±Ø§Øª ØªØ³ÙˆÙŠÙ‚ÙŠØ©"
            ]
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ
design_genius = IntelligentDesigner()

@app.on_event("startup")
async def startup():
    print("ğŸš€ Ø¨Ø¯Ø¡ Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ...")
    await design_genius.connect_to_smartcore()
    
    # ØªØ·ÙˆÙŠØ± Ø°Ø§ØªÙŠ Ø¯ÙˆØ±ÙŠ
    async def periodic_development():
        while True:
            await asyncio.sleep(600)  # ÙƒÙ„ 10 Ø¯Ù‚Ø§Ø¦Ù‚
            await design_genius.self_develop()
    
    asyncio.create_task(periodic_development())

@app.get("/")
async def root():
    return design_genius.get_status()

@app.post("/execute")
async def execute_design_task(task: dict):
    """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© ØªØµÙ…ÙŠÙ… Ù…Ù† Smart Core"""
    try:
        print(f"ğŸ¨ Ù…Ù‡Ù…Ø© ØªØµÙ…ÙŠÙ… Ø¬Ø¯ÙŠØ¯Ø©: {task.get('task_description', 'ØºÙŠØ± Ù…Ø­Ø¯Ø¯')}")
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø·Ù„Ø¨ Ø§Ù„ØªØµÙ…ÙŠÙ…
        result = await design_genius.process_design_order(task)
        
        # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ø³ÙƒØ±ØªÙŠØ±Ø© Ø³ÙØ±ÙˆØ­
        surooh_message = await design_genius.send_to_surooh_chat(result)
        
        return {
            "success": True,
            "design_result": result,
            "surooh_message": surooh_message,
            "message": "ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ… Ø¨Ù†Ø¬Ø§Ø­!",
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        print(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
        return {
            "success": False,
            "error": str(e),
            "message": "ÙØ´Ù„ ÙÙŠ Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„ØªØµÙ…ÙŠÙ…"
        }

@app.get("/design-library")
async def get_design_library():
    """Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªØµØ§Ù…ÙŠÙ…"""
    return {
        "library": design_genius.design_library,
        "total_designs": len(design_genius.design_library),
        "total_size_mb": sum(design.get("size_mb", 0) for design in design_genius.design_library)
    }

@app.get("/generated-images")
async def get_generated_images():
    """Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙÙˆÙ„Ø¯Ø©"""
    return {
        "generated_images": design_genius.generated_images[-20:],  # Ø¢Ø®Ø± 20
        "total": len(design_genius.generated_images)
    }

@app.post("/test-design")
async def test_design_generation():
    """Ø§Ø®ØªØ¨Ø§Ø± ØªÙˆÙ„ÙŠØ¯ ØªØµÙ…ÙŠÙ…"""
    test_request = "ØªØµÙ…ÙŠÙ… Ø´Ø¹Ø§Ø± Ø§Ø­ØªØ±Ø§ÙÙŠ Ù„Ø´Ø±ÙƒØ© ØªÙ‚Ù†ÙŠØ©"
    
    # ØªØ­Ù„ÙŠÙ„
    analysis = await design_genius.intelligent_design_analysis(test_request)
    
    # ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø© Ø§Ø®ØªØ¨Ø§Ø±
    image_result = await design_genius.generate_image_with_dalle(
        analysis["dalle_prompt"],
        analysis["design_type"]
    )
    
    return {
        "success": not bool(image_result.get("error")),
        "test_request": test_request,
        "analysis": analysis,
        "image_result": image_result,
        "message": "ØªÙ… Ø§Ø®ØªØ¨Ø§Ø± Ø§Ù„Ù…ØµÙ…Ù… Ø§Ù„Ø°ÙƒÙŠ!"
    }

@app.get("/creative-knowledge")
async def get_creative_knowledge():
    """Ø§Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠØ©"""
    return {
        "knowledge_base": design_genius.creative_knowledge,
        "learned_patterns": len(design_genius.creative_knowledge["learned_preferences"])
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8004)