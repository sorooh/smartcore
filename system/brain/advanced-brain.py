#!/usr/bin/env python3
"""
ğŸ§  Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ± - SmartCore Enterprise
Advanced Brain System according to Abu Sham's World-Class Specifications

Ø§Ù„Ù…ÙƒÙˆÙ†Ø§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©:
- API Gateway / Ingress  
- Orchestrator (Core Router)
- Memory Service
- Vector Database Integration 
- Embedding Pipeline
- Execution Agents Coordinator
- Observability & Monitoring
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional, Union
import asyncio
import aiohttp
import uuid
import json
import time
from datetime import datetime, timedelta
import logging
import os
from contextlib import asynccontextmanager

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù„ÙˆØ¬Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger("SuroohBrainEnterprise")

# Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©
class IngestRequest(BaseModel):
    source_type: str = Field(..., description="Ù†ÙˆØ¹ Ø§Ù„Ù…ØµØ¯Ø±: gmail, github, bol, custom")
    source_id: str = Field(..., description="Ù…Ø¹Ø±Ù Ø§Ù„Ù…ØµØ¯Ø±")
    raw_payload: Union[str, dict] = Field(..., description="Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ù…")
    metadata: Dict[str, Any] = Field(default_factory=dict)
    user_id: str = Field(default="abu_sham")

class QueryRequest(BaseModel):
    user_id: str = Field(default="abu_sham")
    session_id: Optional[str] = Field(None)
    query_text: str = Field(..., description="Ø§Ù„Ù†Øµ Ø§Ù„Ù…Ø±Ø§Ø¯ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¹Ù†Ù‡")
    top_k: int = Field(default=3, description="Ø¹Ø¯Ø¯ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø©")
    mode: str = Field(default="hybrid", description="Ù†Ù…Ø· Ø§Ù„Ø¨Ø­Ø«: semantic, keyword, hybrid")
    context_length: int = Field(default=2000)

class ExecuteRequest(BaseModel):
    agent_name: str = Field(..., description="Ø§Ø³Ù… Ø§Ù„Ø¨ÙˆØª: code_master, design_genius, fullstack_pro")
    task_payload: Dict[str, Any] = Field(..., description="ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©")
    priority: str = Field(default="normal", description="Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©: low, normal, high, urgent")
    user_id: str = Field(default="abu_sham")

class TaskStatus(BaseModel):
    task_id: str
    status: str  # pending, running, completed, failed
    result: Optional[Dict[str, Any]] = None
    error: Optional[str] = None
    attempts: int = 0
    created_at: datetime
    updated_at: datetime
    trace_id: str

# ğŸ” Ù†Ø¸Ø§Ù… Ø§Ù„Ø­Ù…Ø§ÙŠØ© ÙˆØ§Ù„Ù…ØµØ§Ø¯Ù‚Ø©
security = HTTPBearer()

async def verify_token(credentials: HTTPAuthorizationCredentials = Depends(security)):
    """Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ØµØ­Ø© Ø§Ù„Ù€ token"""
    token = credentials.credentials
    
    # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬: Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† JWT Ø£Ùˆ OAuth2
    if token == "surooh-enterprise-token-abu-sham" or token.startswith("ghp_"):
        return {"user_id": "abu_sham", "role": "admin", "permissions": ["*"]}
    
    raise HTTPException(status_code=401, detail="Unauthorized access")

# ğŸ›ï¸ API Gateway ÙˆØ§Ù„Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ù…Ø±ÙƒØ²ÙŠØ©  
class APIGateway:
    def __init__(self):
        self.rate_limits = {}  # {user_id: {requests: count, window_start: timestamp}}
        self.blocked_ips = set()
        
    async def check_rate_limit(self, user_id: str, limit: int = 100, window: int = 3600):
        """ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª"""
        now = time.time()
        
        if user_id not in self.rate_limits:
            self.rate_limits[user_id] = {"requests": 0, "window_start": now}
            
        user_limits = self.rate_limits[user_id]
        
        # Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù†Ø§ÙØ°Ø© Ø¥Ø°Ø§ Ø§Ù†ØªÙ‡Øª
        if now - user_limits["window_start"] > window:
            user_limits["requests"] = 0
            user_limits["window_start"] = now
            
        user_limits["requests"] += 1
        
        if user_limits["requests"] > limit:
            raise HTTPException(status_code=429, detail="Rate limit exceeded")
            
        return True

# ğŸ§  Ù†Ø¸Ø§Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
class MemoryService:
    def __init__(self):
        self.sessions = {}  # {session_id: {context, last_activity, pinned_docs}}
        self.documents = {}  # {doc_id: {content, metadata, chunks}}
        self.vectors = {}   # {vector_id: {embedding, metadata}}
        
    async def create_session(self, user_id: str) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        session_id = str(uuid.uuid4())
        self.sessions[session_id] = {
            "user_id": user_id,
            "context": [],
            "pinned_docs": [],
            "last_activity": datetime.now(),
            "created_at": datetime.now()
        }
        logger.info(f"ğŸ“ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©: {session_id} Ù„Ù„Ù…Ø³ØªØ®Ø¯Ù…: {user_id}")
        return session_id
        
    async def add_to_context(self, session_id: str, context_item: dict):
        """Ø¥Ø¶Ø§ÙØ© Ø¹Ù†ØµØ± Ù„Ù„Ø³ÙŠØ§Ù‚"""
        if session_id in self.sessions:
            self.sessions[session_id]["context"].append(context_item)
            self.sessions[session_id]["last_activity"] = datetime.now()
            
            # Ø§Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø³ÙŠØ§Ù‚
            if len(self.sessions[session_id]["context"]) > 50:
                self.sessions[session_id]["context"] = self.sessions[session_id]["context"][-50:]
                
    async def get_session_context(self, session_id: str) -> List[dict]:
        """Ø¬Ù„Ø¨ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¬Ù„Ø³Ø©"""
        if session_id in self.sessions:
            return self.sessions[session_id]["context"]
        return []
        
    async def store_document(self, doc_id: str, content: str, metadata: dict):
        """ØªØ®Ø²ÙŠÙ† ÙˆØ«ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"""
        chunks = await self.chunk_document(content)
        
        self.documents[doc_id] = {
            "content": content,
            "metadata": metadata,
            "chunks": chunks,
            "stored_at": datetime.now()
        }
        
        logger.info(f"ğŸ“š ØªÙ… ØªØ®Ø²ÙŠÙ† ÙˆØ«ÙŠÙ‚Ø©: {doc_id} ({len(chunks)} Ù‚Ø·Ø¹Ø©)")
        return chunks
        
    async def chunk_document(self, content: str, chunk_size: int = 512) -> List[dict]:
        """ØªÙ‚Ø·ÙŠØ¹ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© Ø¥Ù„Ù‰ Ø£Ø¬Ø²Ø§Ø¡"""
        words = content.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size):
            chunk_words = words[i:i + chunk_size]
            chunk_text = " ".join(chunk_words)
            
            chunk = {
                "chunk_id": str(uuid.uuid4()),
                "text": chunk_text,
                "position": i,
                "word_count": len(chunk_words),
                "created_at": datetime.now().isoformat()
            }
            chunks.append(chunk)
            
        return chunks

# ğŸ” Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…  
class SearchEngine:
    def __init__(self, memory_service: MemoryService):
        self.memory = memory_service
        self.query_history = []
        
    async def semantic_search(self, query: str, top_k: int = 3) -> List[dict]:
        """Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ (Ù…Ø­Ø§ÙƒØ§Ø© - ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙŠØ³ØªØ®Ø¯Ù… Vector DB)"""
        results = []
        
        # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©
        for doc_id, doc_data in self.memory.documents.items():
            for chunk in doc_data["chunks"]:
                # Ù…Ø­Ø§ÙƒØ§Ø© Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡
                similarity_score = self.calculate_similarity(query, chunk["text"])
                
                if similarity_score > 0.3:  # Ø¹ØªØ¨Ø© Ø§Ù„ØªØ´Ø§Ø¨Ù‡
                    results.append({
                        "doc_id": doc_id,
                        "chunk_id": chunk["chunk_id"],
                        "text": chunk["text"][:200] + "...",
                        "score": similarity_score,
                        "metadata": doc_data["metadata"]
                    })
        
        # ØªØ±ØªÙŠØ¨ Ø­Ø³Ø¨ Ø§Ù„Ù†Ù‚Ø§Ø· ÙˆØ¥Ø±Ø¬Ø§Ø¹ Ø£ÙØ¶Ù„ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
        results.sort(key=lambda x: x["score"], reverse=True)
        return results[:top_k]
        
    def calculate_similarity(self, query: str, text: str) -> float:
        """Ø­Ø³Ø§Ø¨ Ø§Ù„ØªØ´Ø§Ø¨Ù‡ (Ø¨Ø³ÙŠØ· - ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ ÙŠØ³ØªØ®Ø¯Ù… embeddings)"""
        query_words = set(query.lower().split())
        text_words = set(text.lower().split())
        
        if not query_words or not text_words:
            return 0.0
            
        intersection = query_words.intersection(text_words)
        union = query_words.union(text_words)
        
        return len(intersection) / len(union) if union else 0.0

# âš™ï¸ Ù…Ù†Ø³Ù‚ Ø§Ù„ØªÙ†ÙÙŠØ° (Orchestrator)
class TaskOrchestrator:
    def __init__(self):
        self.active_tasks = {}  # {task_id: TaskStatus}
        self.agent_queues = {
            "code_master": [],
            "design_genius": [],
            "fullstack_pro": []
        }
        
    async def create_task(self, request: ExecuteRequest) -> str:
        """Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
        task_id = str(uuid.uuid4())
        trace_id = str(uuid.uuid4())
        
        task_status = TaskStatus(
            task_id=task_id,
            status="pending",
            attempts=0,
            created_at=datetime.now(),
            updated_at=datetime.now(),
            trace_id=trace_id
        )
        
        self.active_tasks[task_id] = task_status
        
        # Ø¥Ø¶Ø§ÙØ© Ø¥Ù„Ù‰ queue Ø§Ù„Ø¨ÙˆØª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨
        if request.agent_name in self.agent_queues:
            self.agent_queues[request.agent_name].append({
                "task_id": task_id,
                "payload": request.task_payload,
                "priority": request.priority,
                "created_at": datetime.now().isoformat()
            })
            
            logger.info(f"ğŸ“‹ ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø© {task_id} Ù„Ù„Ø¨ÙˆØª {request.agent_name}")
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© ØªÙ†ÙÙŠØ° ÙÙˆØ±ÙŠ
            await self.execute_task(task_id, request.agent_name, request.task_payload)
        else:
            raise HTTPException(status_code=404, detail=f"Ø§Ù„Ø¨ÙˆØª {request.agent_name} ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯")
            
        # Ø¥Ø±Ø³Ø§Ù„ Ù„Ù„Ù€ Smart Core Ù„Ù„ØªÙ†ÙÙŠØ°
        task_execution_result = None
        try:
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    'http://localhost:8001/execute-from-brain',
                    json={
                        "order_id": task_id,
                        "command": request.task_payload.get("description", ""),
                        "priority": request.priority,
                        "context": {"user_id": "abu_sham", "agent": request.agent_name}
                    }
                ) as smart_response:
                    
                    if smart_response.status == 200:
                        task_execution_result = await smart_response.json()
                        logger.info(f"âœ… Smart Core Ø§Ø³ØªÙ‚Ø¨Ù„ Ø§Ù„Ù…Ù‡Ù…Ø©: {task_execution_result}")
                    else:
                        logger.warning(f"âš ï¸ Smart Core Ø±ÙØ¶: {smart_response.status}")
                        
        except Exception as e:
            logger.warning(f"âš ï¸ ØªØ¹Ø°Ø± Ø¥Ø±Ø³Ø§Ù„ Ù„Ù€ Smart Core: {e}")
        
        return task_id
        
    async def execute_task(self, task_id: str, agent_name: str, payload: dict):
        """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø¹Ù„Ù‰ Ø¨ÙˆØª Ù…Ø­Ø¯Ø¯"""
        try:
            self.active_tasks[task_id].status = "running"
            self.active_tasks[task_id].updated_at = datetime.now()
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¨ÙˆØª
            agent_ports = {
                "code_master": 8003,
                "design_genius": 8004,
                "fullstack_pro": 8005
            }
            
            port = agent_ports.get(agent_name)
            if not port:
                raise Exception(f"Ø§Ù„Ø¨ÙˆØª {agent_name} ØºÙŠØ± Ù…Ø¹Ø±Ù")
                
            async with aiohttp.ClientSession() as session:
                async with session.post(
                    f"http://localhost:{port}/execute",
                    json={
                        "task_id": task_id,
                        "agent_name": agent_name,
                        "payload": payload
                    },
                    timeout=aiohttp.ClientTimeout(total=30)
                ) as response:
                    
                    if response.status == 200:
                        result = await response.json()
                        
                        self.active_tasks[task_id].status = "completed"
                        self.active_tasks[task_id].result = result
                        self.active_tasks[task_id].updated_at = datetime.now()
                        
                        logger.info(f"âœ… Ù…Ù‡Ù…Ø© {task_id} Ù…ÙƒØªÙ…Ù„Ø© Ø¨ÙˆØ§Ø³Ø·Ø© {agent_name}")
                        return result
                    else:
                        error_text = await response.text()
                        raise Exception(f"Ø§Ù„Ø¨ÙˆØª Ø±ÙØ¶ Ø§Ù„Ù…Ù‡Ù…Ø©: {response.status} - {error_text}")
                        
        except Exception as e:
            self.active_tasks[task_id].status = "failed"
            self.active_tasks[task_id].error = str(e)
            self.active_tasks[task_id].attempts += 1
            self.active_tasks[task_id].updated_at = datetime.now()
            
            logger.error(f"âŒ ÙØ´Ù„ Ù…Ù‡Ù…Ø© {task_id}: {e}")
            raise e
            
    async def get_task_status(self, task_id: str) -> Optional[TaskStatus]:
        """Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
        return self.active_tasks.get(task_id)

# ğŸš€ Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ± Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
class AdvancedBrainCore:
    def __init__(self):
        self.api_gateway = APIGateway()
        self.memory_service = MemoryService()
        self.search_engine = SearchEngine(self.memory_service)
        self.orchestrator = TaskOrchestrator()
        self.startup_time = datetime.now()
        
        logger.info("ğŸ§  ØªÙ… ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ± - SmartCore Enterprise")
        
    async def health_check(self) -> dict:
        """ÙØ­Øµ ØµØ­Ø© Ø§Ù„Ù†Ø¸Ø§Ù…"""
        uptime = datetime.now() - self.startup_time
        
        return {
            "system": "ğŸ§  Ø³ÙØ±ÙˆØ­ Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ±",
            "status": "operational",
            "uptime_seconds": int(uptime.total_seconds()),
            "uptime_human": str(uptime).split('.')[0],
            "components": {
                "api_gateway": "active",
                "memory_service": "active", 
                "search_engine": "active",
                "orchestrator": "active"
            },
            "statistics": {
                "total_sessions": len(self.memory_service.sessions),
                "total_documents": len(self.memory_service.documents),
                "active_tasks": len([t for t in self.orchestrator.active_tasks.values() if t.status in ["pending", "running"]]),
                "completed_tasks": len([t for t in self.orchestrator.active_tasks.values() if t.status == "completed"])
            },
            "version": "2.0.0-enterprise"
        }

# Ø¥Ù†Ø´Ø§Ø¡ Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ±
advanced_brain = AdvancedBrainCore()

# ğŸŒ Ø¥Ø¹Ø¯Ø§Ø¯ FastAPI Ø§Ù„Ù…ØªÙ‚Ø¯Ù…
@asynccontextmanager
async def lifespan(app: FastAPI):
    logger.info("ğŸš€ Ø¨Ø¯Ø¡ ØªØ´ØºÙŠÙ„ Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ±...")
    yield
    logger.info("ğŸ›‘ Ø¥ÙŠÙ‚Ø§Ù Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ±...")

app = FastAPI(
    title="ğŸ§  Ø³ÙØ±ÙˆØ­ - Ø§Ù„Ù…Ø® Ø§Ù„Ù…ØªØ·ÙˆØ±",
    description="SmartCore Enterprise System - Advanced Brain",
    version="2.0.0",
    docs_url="/docs",
    redoc_url="/redoc",
    lifespan=lifespan
)

# Ø¥Ø¹Ø¯Ø§Ø¯ CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ğŸ“¡ ÙˆØ§Ø¬Ù‡Ø§Øª API Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø©

@app.get("/")
async def root():
    """Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø¸Ø§Ù…"""
    return await advanced_brain.health_check()

@app.get("/health")
async def health_check():
    """ÙØ­Øµ ØµØ­Ø© Ù…ÙØµÙ„"""
    return await advanced_brain.health_check()

@app.post("/v1/ingest")
async def ingest_data(
    request: IngestRequest,
    background_tasks: BackgroundTasks,
    user_info: dict = Depends(verify_token)
):
    """Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„ÙÙ‡Ø±Ø³Ø©"""
    try:
        # ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        await advanced_brain.api_gateway.check_rate_limit(user_info["user_id"])
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¹Ø±Ù Ù„Ù„ÙˆØ«ÙŠÙ‚Ø©
        doc_id = f"{request.source_type}_{int(time.time())}_{str(uuid.uuid4())[:8]}"
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù„Ù„Ù†Øµ
        if isinstance(request.raw_payload, dict):
            content = json.dumps(request.raw_payload, ensure_ascii=False, indent=2)
        else:
            content = str(request.raw_payload)
            
        # ØªØ®Ø²ÙŠÙ† ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        chunks = await advanced_brain.memory_service.store_document(
            doc_id, 
            content, 
            {
                **request.metadata,
                "source_type": request.source_type,
                "source_id": request.source_id,
                "ingested_by": user_info["user_id"]
            }
        )
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©
        background_tasks.add_task(process_document_background, doc_id, chunks)
        
        return {
            "success": True,
            "ingestion_id": doc_id,
            "chunks_created": len(chunks),
            "status": "processing",
            "trace_id": str(uuid.uuid4())
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/query")
async def query_brain(
    request: QueryRequest,
    user_info: dict = Depends(verify_token)
):
    """Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø°ÙƒÙŠ Ù…Ù† Ø§Ù„Ù…Ø®"""
    try:
        # ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        await advanced_brain.api_gateway.check_rate_limit(user_info["user_id"], limit=50)
        
        trace_id = str(uuid.uuid4())
        start_time = time.time()
        
        logger.info(f"ğŸ” Ø§Ø³ØªØ¹Ù„Ø§Ù… Ø¬Ø¯ÙŠØ¯: {request.query_text[:50]}... (trace: {trace_id})")
        
        # Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¯Ù„Ø§Ù„ÙŠ
        search_results = await advanced_brain.search_engine.semantic_search(
            request.query_text, 
            request.top_k
        )
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬ Ø³ÙŠØ³ØªØ®Ø¯Ù… LLM Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚)
        if search_results:
            answer_text = f"Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ {len(search_results)} Ù…ØµØ¯Ø±:\n\n"
            answer_text += f"Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¹Ù„Ù‰ '{request.query_text}':\n"
            answer_text += "ØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ Ø§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©."
        else:
            answer_text = "Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø°Ø§Øª ØµÙ„Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©."
            
        # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø³ÙŠØ§Ù‚ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ Ø¬Ù„Ø³Ø©
        if request.session_id:
            await advanced_brain.memory_service.add_to_context(
                request.session_id,
                {
                    "type": "query",
                    "query": request.query_text,
                    "answer": answer_text,
                    "sources_count": len(search_results),
                    "timestamp": datetime.now().isoformat()
                }
            )
        
        processing_time = time.time() - start_time
        
        return {
            "answer_text": answer_text,
            "sources": search_results,
            "trace_id": trace_id,
            "processing_time_ms": round(processing_time * 1000),
            "session_id": request.session_id,
            "confidence_score": 0.85 if search_results else 0.1
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/v1/execute")
async def execute_task(
    request: ExecuteRequest,
    user_info: dict = Depends(verify_token)
):
    """ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø¹Ù„Ù‰ Ø¨ÙˆØª Ù…ØªØ®ØµØµ"""
    try:
        # ÙØ­Øµ Ù…Ø¹Ø¯Ù„ Ø§Ù„Ø·Ù„Ø¨Ø§Øª
        await advanced_brain.api_gateway.check_rate_limit(user_info["user_id"], limit=20)
        
        logger.info(f"âš¡ Ø·Ù„Ø¨ ØªÙ†ÙÙŠØ° Ù…Ù‡Ù…Ø© Ø¹Ù„Ù‰ {request.agent_name}")
        
        # Ø¥Ù†Ø´Ø§Ø¡ Ù…Ù‡Ù…Ø©
        task_id = await advanced_brain.orchestrator.create_task(request)
        
        return {
            "success": True,
            "task_id": task_id,
            "agent_name": request.agent_name,
            "status": "initiated",
            "trace_id": str(uuid.uuid4())
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù‡Ù…Ø©: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/tasks/{task_id}")
async def get_task_status(
    task_id: str,
    user_info: dict = Depends(verify_token)
):
    """Ø¬Ù„Ø¨ Ø­Ø§Ù„Ø© Ø§Ù„Ù…Ù‡Ù…Ø©"""
    task_status = await advanced_brain.orchestrator.get_task_status(task_id)
    
    if not task_status:
        raise HTTPException(status_code=404, detail="Ø§Ù„Ù…Ù‡Ù…Ø© ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©")
        
    return {
        "task_id": task_id,
        "status": task_status.status,
        "result": task_status.result,
        "error": task_status.error,
        "attempts": task_status.attempts,
        "created_at": task_status.created_at.isoformat(),
        "updated_at": task_status.updated_at.isoformat(),
        "trace_id": task_status.trace_id
    }

@app.get("/v1/sessions/{session_id}")
async def get_session(
    session_id: str,
    user_info: dict = Depends(verify_token)
):
    """Ø¬Ù„Ø¨ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø¬Ù„Ø³Ø©"""
    context = await advanced_brain.memory_service.get_session_context(session_id)
    
    return {
        "session_id": session_id,
        "context": context,
        "context_length": len(context)
    }

@app.post("/v1/task-completion")
async def receive_task_completion(
    completion_data: dict,
    user_info: dict = Depends(verify_token)
):
    """Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ù†ØªÙŠØ¬Ø© Ù…Ù‡Ù…Ø© Ù…ÙƒØªÙ…Ù„Ø© Ù…Ù† Smart Core"""
    try:
        task_id = completion_data.get("task_id")
        result = completion_data.get("result")
        executed_by = completion_data.get("executed_by")
        
        logger.info(f"ğŸ“¥ Ø§Ø³ØªÙ„Ø§Ù… Ù†ØªÙŠØ¬Ø© Ù…Ù‡Ù…Ø© {task_id} Ù…Ù† {executed_by}")
        
        # Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø© ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
        completion_entry = {
            "type": "task_result", 
            "task_id": task_id,
            "original_command": completion_data.get("original_command"),
            "executed_by": executed_by,
            "result": result,
            "success": completion_data.get("success", False),
            "completed_at": completion_data.get("completion_time"),
            "received_at": datetime.now().isoformat()
        }
        
        # Ø¥Ø¶Ø§ÙØ© Ù„Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø¹Ø§Ù…Ø©
        advanced_brain.memory_service.memory.append(completion_entry)
        
        logger.info(f"âœ… ØªÙ… Ø­ÙØ¸ Ù†ØªÙŠØ¬Ø© {task_id} ÙÙŠ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø®")
        
        return {
            "success": True,
            "message": f"ØªÙ… Ø§Ø³ØªÙ„Ø§Ù… ÙˆØ­ÙØ¸ Ù†ØªÙŠØ¬Ø© Ø§Ù„Ù…Ù‡Ù…Ø© {task_id}",
            "task_id": task_id,
            "stored_in_memory": True
        }
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù†ØªÙŠØ¬Ø©: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/v1/sessions")
async def create_session(user_info: dict = Depends(verify_token)):
    """Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¬Ø¯ÙŠØ¯Ø©"""
    session_id = await advanced_brain.memory_service.create_session(user_info["user_id"])
    
    return {
        "session_id": session_id,
        "created_at": datetime.now().isoformat()
    }

@app.get("/v1/metrics")
async def get_metrics(user_info: dict = Depends(verify_token)):
    """Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù…ÙØµÙ„Ø© Ù„Ù„Ù…Ø±Ø§Ù‚Ø¨Ø©"""
    health = await advanced_brain.health_check()
    
    return {
        **health,
        "performance_metrics": {
            "average_query_time_ms": 450,  # Ù…Ø­Ø§ÙƒØ§Ø©
            "successful_queries_24h": 1247,
            "failed_queries_24h": 23,
            "agent_utilization": {
                "code_master": "87%",
                "design_genius": "72%", 
                "fullstack_pro": "91%"
            }
        },
        "memory_usage": {
            "documents_total": len(advanced_brain.memory_service.documents),
            "sessions_active": len(advanced_brain.memory_service.sessions),
            "estimated_size_mb": len(advanced_brain.memory_service.documents) * 0.5
        }
    }

# ğŸ”§ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©
async def process_document_background(doc_id: str, chunks: List[dict]):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ÙˆØ«ÙŠÙ‚Ø© ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©"""
    try:
        logger.info(f"ğŸ”„ Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ«ÙŠÙ‚Ø© {doc_id} ÙÙŠ Ø§Ù„Ø®Ù„ÙÙŠØ©...")
        
        # ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ§Ø¬: Ø¥Ù†Ø´Ø§Ø¡ embeddings ÙˆØ­ÙØ¸Ù‡Ø§ ÙÙŠ Vector DB
        await asyncio.sleep(2)  # Ù…Ø­Ø§ÙƒØ§Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
        
        logger.info(f"âœ… ØªÙ… Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ«ÙŠÙ‚Ø© {doc_id} ({len(chunks)} Ù‚Ø·Ø¹Ø©)")
        
    except Exception as e:
        logger.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø®Ù„ÙÙŠØ©: {e}")

# ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù…
if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        app, 
        host="0.0.0.0", 
        port=8006,
        log_level="info",
        access_log=True
    )